{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213
    },
    "colab_type": "code",
    "id": "90OU2SDJL2Q9",
    "outputId": "89d239d4-dc97-43c7-fff0-cbbe793bf094"
   },
   "outputs": [],
   "source": [
    "# Pip install Tweepy if you don't already have the package\n",
    "# !pip install tweepy\n",
    "# conda install -c conda-forge tweepy\n",
    "# conda install -c ranaroussi yfinance\n",
    "# conda install -c conda-forge textblob\n",
    "\n",
    "# Imports\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "import yfinance as yf\n",
    "from textblob import TextBlob as tb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xh92xbMkLy28"
   },
   "source": [
    "# Scraper for Twitter using Tweepy\n",
    "\n",
    "Package Github: https://github.com/tweepy/tweepy\n",
    "\n",
    "Package Documentation: https://tweepy.readthedocs.io/en/latest/\n",
    "\n",
    "### Notebook Author: Martin Beck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5q3dtxauP0KR"
   },
   "source": [
    "## Credentials and Authorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4NcOQy9XM5hR"
   },
   "outputs": [],
   "source": [
    "# Credentials\n",
    "\n",
    "consumer_key = \"xxx\"\n",
    "consumer_secret = \"xxx\"\n",
    "access_token = \"xxx\"\n",
    "access_token_secret = \"xxx\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LvBbNQXgM3QI"
   },
   "source": [
    "## Query by Username\n",
    "Creation of queries using Tweepy API\n",
    "\n",
    "Function is focused on completing the query then providing a CSV file of that query using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fguMqU2ifc5h"
   },
   "outputs": [],
   "source": [
    "tweets = []\n",
    "\n",
    "def username_tweets_to_csv(username,count):\n",
    "    try: \n",
    "    # Pulling individual tweets from query\n",
    "        for tweet in api.user_timeline(id=username, count=count):\n",
    "\n",
    "            # Adding to list that contains all tweets\n",
    "            first_letter = tweet.text[0][0]\n",
    "            if 'RT @' not in tweet.text and '@' not in first_letter and 'https:' not in tweet.text:\n",
    "                tweets.append((tweet.created_at,tweet.id,tweet.text))\n",
    "\n",
    "            # Creation of dataframe from tweets list\n",
    "            tweetsdf = pd.DataFrame(tweets,columns=['Datetime', 'Tweet Id', 'Text'])\n",
    "\n",
    "            # Converting dataframe to CSV\n",
    "            tweetsdf.to_csv('{}-tweets.csv'.format(username)) \n",
    "\n",
    "    except BaseException as e:\n",
    "          print('failed on_status,',str(e))\n",
    "          time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jFe9EonmM6u9"
   },
   "source": [
    "## Query by Text Search\n",
    "Function is focused on completing the query then providing a CSV file of that query using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1hOeCFq6M83k"
   },
   "outputs": [],
   "source": [
    "tweets = []\n",
    "\n",
    "def text_query_to_csv(text_query,count):\n",
    "    try:\n",
    "    # Pulling individual tweets from query\n",
    "        for tweet in api.search(q=text_query, count=count):\n",
    "\n",
    "          # Adding to list that contains all tweets\n",
    "          tweets.append((tweet.created_at,tweet.id,tweet.text))\n",
    "\n",
    "          # Creation of dataframe from tweets list\n",
    "          tweetsdf = pd.DataFrame(tweets,columns=['Datetime', 'Tweet Id', 'Text'])\n",
    "\n",
    "          # Converting dataframe to CSV\n",
    "          tweetsdf.to_csv('{}-tweets.csv'.format(text_query)) \n",
    "\n",
    "    except BaseException as e:\n",
    "        print('failed on_status,',str(e))\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wJcKa7Wrk_e2"
   },
   "source": [
    "## Query Function Calls\n",
    "Putting it all together and using functions created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GT3fFlfhleIN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input username to scrape tweets and name csv file\n",
    "# Max recent tweets pulls x amount of most recent tweets from that user\n",
    "username = 'donaldtrump'\n",
    "count = 50\n",
    "\n",
    "# Calling function to turn username's past X amount of tweets into a CSV file\n",
    "username_tweets_to_csv(username, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dgK3Am48leWF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input search query to scrape tweets and name csv file\n",
    "# Max recent tweets pulls x amount of most recent tweets from that user\n",
    "text_query = 'tesla'\n",
    "count = 150\n",
    "\n",
    "# Calling function to query X amount of relevant tweets and create a CSV file\n",
    "text_query_to_csv(text_query, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFromCSV(username):\n",
    "    tweet_list = []\n",
    "    date_list = []\n",
    "    final_list = []\n",
    "    with open(username + '-tweets.csv', newline='') as csvfile:\n",
    "        spamreader = csv.reader(csvfile)\n",
    "        next(spamreader, None)\n",
    "        for row in spamreader:\n",
    "            #print(', '.join(row))\n",
    "            date = row[1]\n",
    "            tweet = row[3]\n",
    "            firstletter = tweet[0][0]\n",
    "            secondletter = tweet[:2]\n",
    "            if \"@\" not in firstletter and \"RT\" not in secondletter:\n",
    "                #print (\"date: \" + date + \" tweet: \" + tweet)\n",
    "                tweet_list.append(tweet) \n",
    "                date_list.append(date)\n",
    "            #print (row[3])\n",
    "            #print (len(row))\n",
    "        final_list.append(tweet_list)\n",
    "        final_list.append(date_list)\n",
    "        return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-160-25ff460a81f0>, line 7)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-160-25ff460a81f0>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    if sentiment_score <= - 0.5 or sentiment_score >= 0.5:\u001b[0m\n\u001b[0m                                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "tweet_list = readFromCSV('donaldtrump')[0]\n",
    "#print(tweet_list)\n",
    "negative_list = []\n",
    "positve_list = []\n",
    "for tweet in tweet_list:\n",
    "    blob = tb(tweet)\n",
    "    sentiment_score = blob.sentiment.polarity\n",
    "    print(\"tweet: \" + tweet + \"\\n\" + \"sentiment score: \" + str(sentiment_score))\n",
    "    if sentiment_score <= -0.5:\n",
    "        negative_list\n",
    "    elif sentiment_score >= 0.5:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Open    High     Low   Close     Volume  Dividends  Stock Splits\nDate                                                                          \n2020-06-26  306.16  306.39  299.42  300.05  127961000          0             0\n2020-06-29  301.41  304.61  298.93  304.46   79773300          0             0\n2020-06-30  303.99  310.20  303.82  308.36  113394800          0             0\n2020-07-01  309.57  311.89  309.07  310.52   72396500          0             0\n2020-07-02  314.24  315.70  311.51  312.23   69344200          0             0\n[*********************100%***********************]  1 of 1 completed\n"
    }
   ],
   "source": [
    "thisdict = {\n",
    "  \"elonmusk\": \"TSLA\",\n",
    "  \"jack\": \"TWTR\",\n",
    "  \"satyanadella\": \"MSFT\",\n",
    "  \"tim_cook\": \"AAPL\",\n",
    "  \"JeffBezos\": \"AMZN\",\n",
    "  \"sundarpichai\": \"GOOGL\",\n",
    "  \"donaldtrump\": \"SPY\"\n",
    "}\n",
    "\n",
    "msft = yf.Ticker(\"SPY\")\n",
    "\n",
    "# get stock info\n",
    "#print(msft.info)\n",
    "\n",
    "# get historical market data\n",
    "hist = msft.history(period=\"5d\")\n",
    "\n",
    "print(hist)\n",
    "\n",
    "data_df = yf.download(\"AAPL\", start=\"2020-02-01\", end=\"2020-03-20\")\n",
    "data_df.to_csv('aapl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Tweepy Twitter Scraper",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}